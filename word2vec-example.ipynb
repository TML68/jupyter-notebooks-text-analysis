{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'txt/0426.txt'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "all_txt_files =[]\n",
    "# get all file names for obits in txt folder\n",
    "for root, dirs, files in os.walk(\"txt\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\"):\n",
    "            all_txt_files.append(os.path.join(root, file))\n",
    "n_files = len(all_txt_files)\n",
    "all_txt_files[365]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of strings. Each string is an obit\n",
    "all_text = []\n",
    "for i in all_txt_files:\n",
    "    with open(i) as f:\n",
    "        txt = f.read()\n",
    "    all_text.append(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import modules\n",
    "import gensim\n",
    "import multiprocessing\n",
    "\n",
    "# check number of CPUs\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "# define a function to tokenize, lowercase all, remove punctuation, remove numbers etc.\n",
    "def text_cleanup(mystring):\n",
    "    x = ['SPACE', 'PUNCT', 'SYM', 'X', 'NUM']\n",
    "    doc = nlp(mystring.lower())\n",
    "    processed = [i for i in doc if i.pos_ not in x]\n",
    "    processed = [i.text for i in processed if i.is_stop != True]\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code will take a long time to execute ... \n",
    "all_docs = [text_cleanup(i) for i in all_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-15 17:29:56,518 : INFO : collecting all words and their counts\n",
      "2018-11-15 17:29:56,519 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-11-15 17:29:56,597 : INFO : collected 35901 word types from a corpus of 454105 raw words and 366 sentences\n",
      "2018-11-15 17:29:56,597 : INFO : Loading a fresh vocabulary\n",
      "2018-11-15 17:29:56,642 : INFO : min_count=2 retains 21801 unique words (60% of original 35901, drops 14100)\n",
      "2018-11-15 17:29:56,643 : INFO : min_count=2 leaves 440005 word corpus (96% of original 454105, drops 14100)\n",
      "2018-11-15 17:29:56,725 : INFO : deleting the raw counts dictionary of 35901 items\n",
      "2018-11-15 17:29:56,727 : INFO : sample=0.001 downsamples 12 most-common words\n",
      "2018-11-15 17:29:56,727 : INFO : downsampling leaves estimated 426319 word corpus (96.9% of prior 440005)\n",
      "2018-11-15 17:29:56,776 : INFO : estimated required memory for 21801 words and 500 dimensions: 98104500 bytes\n",
      "2018-11-15 17:29:56,777 : INFO : resetting layer weights\n",
      "2018-11-15 17:29:57,316 : INFO : training model with 8 workers on 21801 vocabulary and 500 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2018-11-15 17:29:57,761 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-11-15 17:29:57,763 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-11-15 17:29:57,791 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-11-15 17:29:57,792 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-11-15 17:29:57,794 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-15 17:29:57,817 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-15 17:29:57,820 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-15 17:29:57,824 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-15 17:29:57,825 : INFO : EPOCH - 1 : training on 454105 raw words (418878 effective words) took 0.5s, 828742 effective words/s\n",
      "2018-11-15 17:29:58,259 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-11-15 17:29:58,262 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-11-15 17:29:58,267 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-11-15 17:29:58,286 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-11-15 17:29:58,295 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-15 17:29:58,305 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-15 17:29:58,308 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-15 17:29:58,315 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-15 17:29:58,315 : INFO : EPOCH - 2 : training on 454105 raw words (418720 effective words) took 0.5s, 860326 effective words/s\n",
      "2018-11-15 17:29:58,752 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-11-15 17:29:58,755 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-11-15 17:29:58,763 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-11-15 17:29:58,777 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-11-15 17:29:58,781 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-15 17:29:58,798 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-15 17:29:58,801 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-15 17:29:58,803 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-15 17:29:58,803 : INFO : EPOCH - 3 : training on 454105 raw words (418827 effective words) took 0.5s, 864584 effective words/s\n",
      "2018-11-15 17:29:59,252 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-11-15 17:29:59,253 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-11-15 17:29:59,263 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-11-15 17:29:59,276 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-11-15 17:29:59,276 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-15 17:29:59,297 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-15 17:29:59,298 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-15 17:29:59,301 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-15 17:29:59,301 : INFO : EPOCH - 4 : training on 454105 raw words (418830 effective words) took 0.5s, 849867 effective words/s\n",
      "2018-11-15 17:29:59,743 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-11-15 17:29:59,744 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-11-15 17:29:59,753 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-11-15 17:29:59,763 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-11-15 17:29:59,773 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-11-15 17:29:59,784 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-11-15 17:29:59,786 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-11-15 17:29:59,792 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-11-15 17:29:59,793 : INFO : EPOCH - 5 : training on 454105 raw words (418906 effective words) took 0.5s, 857598 effective words/s\n",
      "2018-11-15 17:29:59,794 : INFO : training on a 2270525 raw words (2094161 effective words) took 2.5s, 845243 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(all_docs, size=500, window=6, min_count=2, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lavin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('girl', 0.9990344047546387),\n",
       " ('write', 0.998995840549469),\n",
       " ('unrequited', 0.9988707304000854),\n",
       " ('friends', 0.9986531138420105),\n",
       " (\"'re\", 0.9984126091003418),\n",
       " ('read', 0.9983095526695251),\n",
       " ('pickford', 0.9982596635818481),\n",
       " ('nightingale', 0.9982486367225647),\n",
       " ('recalled', 0.9981932044029236),\n",
       " ('live', 0.9981801509857178)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lavin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8615039758465234"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('woman', 'man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lavin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.995969269476518"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('success', 'wealth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
